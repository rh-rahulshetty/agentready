# AgentReady v3.0 - Feature Set Proposal

**Date**: 2025-12-02
**Purpose**: Final feature set confirmation before implementation
**Timeline**: 8-10 weeks to stable v3.0.0

---

## Your Requirements (From Critical Decisions)

1. **GitHub Workflow**: Keep GHA labeling behavior (PR-based)
2. **Timeline**: Phased plan toward complete v3.0 (8-10 weeks)
3. **AWS**: Infrastructure only (no code dependencies)
4. **Judge LLM**: Validator primary + Generator/Ensemble as options
5. **Feature Focus**: **2-3 highlight features maximum**

---

## Proposed v3.0 Core Features

### Feature 1: `agentready align` - Automated Alignment âœ¨

**What it does:**
- Automatically fixes failing attributes in repositories
- Creates PR with fixes for user review
- Interactive approval (approve/reject each attribute fix)
- Safe rollback via git stash
- Supports both template-based and AI-powered fixes

**User workflow:**
```bash
# Run align on current repository
$ agentready align .

Analyzing repository...
Found 8 failing attributes that can be fixed.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Attribute 1.1: CLAUDE.md Documentation
Status: FAIL (0/100)

Proposed fix:
  â€¢ Create CLAUDE.md with project overview
  â€¢ Add development setup instructions
  â€¢ Include testing guidelines

Preview:
  + CLAUDE.md (248 lines)

Apply this fix? [Y/n/d(iff)/s(kip all)] y
âœ“ Fix applied

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Attribute 1.2: README Sections
Status: PARTIAL (45/100)

Proposed fix:
  â€¢ Add "Installation" section
  â€¢ Add "Quick Start" section
  â€¢ Add "Contributing" section

Preview:
  M README.md (+ 89 lines, - 2 lines)

Apply this fix? [Y/n/d/s] d

[Shows unified diff...]

Apply this fix? [Y/n/s] y
âœ“ Fix applied

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Summary:
  8 attributes reviewed
  6 fixes applied
  2 skipped

Creating pull request...
âœ“ PR created: https://github.com/org/repo/pull/123

Labels applied:
  â€¢ agentready:align
  â€¢ agentready:automated
  â€¢ tier-1

Review and merge when ready!
```

**Scope for v3.0:**
- 14-16 fixable attributes (Tier 1 + select Tier 2)
  - Template-based: CLAUDE.md, README, .gitignore, structure, lockfiles, conventional commits (6-8 attrs)
  - AI-powered: Type hints, docstrings, test coverage, complexity (6-8 attrs)
- Interactive approval with diff preview
- PR creation with GHA labels
- Git stash backup/rollback
- Dry-run mode (preview without applying)

**Deferred to v3.1+:**
- Automatic PR merge
- Scheduled/continuous alignment
- Remaining 9-11 attributes

---

### Feature 2: Multi-Mode Judge LLM Integration ðŸ¤–

**What it does:**
- Validates AI-generated fixes before applying
- Supports multiple judge modes (validator/generator/ensemble)
- Confidence scoring and quality gates
- Configurable LLM provider (Claude, GPT-4, local models)

**User workflow:**

**Mode A: Validator (Default, Safest)**
```bash
$ agentready align . --judge validator

[Claude generates fix for attribute 2.3: Type Annotations]

Validating fix with judge LLM...
  Correctness: 0.92
  Safety: 0.95
  Style: 0.88
  Overall confidence: 0.91 âœ“

Apply this fix? [Y/n/d/s] y
```

**Mode B: Generator (Alternative LLM)**
```bash
$ agentready align . --judge generator --judge-model gpt-4

[GPT-4 generates fix instead of Claude]

Fix generated by gpt-4
  Confidence: 0.89 âœ“

Apply this fix? [Y/n/d/s] y
```

**Mode C: Ensemble (Both, Pick Best)**
```bash
$ agentready align . --judge ensemble

Generating fixes with multiple LLMs...
  âœ“ Claude Sonnet 4.5: confidence 0.87
  âœ“ GPT-4: confidence 0.91

Selected: GPT-4 (higher confidence)

Apply this fix? [Y/n/d/s] y
```

**Configuration:**
```yaml
# .agentready-config.yaml
align:
  judge:
    enabled: true
    mode: validator              # validator|generator|ensemble
    provider: anthropic          # anthropic|openai|local
    confidence_threshold: 0.85   # Reject fixes below this

    # Ensemble mode settings
    ensemble:
      providers: [anthropic, openai]
      selection_strategy: highest_confidence  # or consensus
```

**Scope for v3.0:**
- All 3 judge modes (validator, generator, ensemble)
- Support for Anthropic (Claude) and OpenAI (GPT-4)
- Confidence scoring (0.0-1.0)
- Configurable thresholds
- CLI flags for mode selection

**Deferred to v3.1+:**
- Local model support (Ollama, llama.cpp)
- Custom judge models (fine-tuned for specific repos)
- Judge learning (improve based on user feedback)

---

### Feature 3: Policy Enforcement ðŸ›¡ï¸

**What it does:**
- Define org-wide alignment policies
- Enforce minimum scores and required attributes
- Block PRs that violate policy
- GitHub Action integration for CI/CD gates

**User workflow:**

**Define Policy (Org Admin)**
```yaml
# .agentready-config.yaml (org level)
policy:
  enabled: true
  enforcement_mode: blocking  # or warning

  # Required attributes that must pass
  required_attributes:
    tier_1: all              # All Tier 1 required
    tier_2: ["2.1", "2.3"]   # Specific Tier 2 required

  # Score gates
  score_gates:
    minimum_score: 75        # Gold certification required
    tier_thresholds:
      tier_1: 90             # Tier 1 avg must be 90+
      tier_2: 70             # Tier 2 avg must be 70+

  # Exemptions
  exemptions:
    repos: ["legacy-app", "experimental/*"]
    attributes: ["3.5"]  # Exempt specific attributes
```

**Developer Workflow (PR Check)**
```bash
# In GitHub Actions (automatic)
$ agentready align . --policy-check

Checking policy compliance...

âŒ Policy Violation: Repository does not meet policy requirements

Required Attributes Failing:
  â€¢ 1.1: CLAUDE.md Documentation (0/100) - REQUIRED
  â€¢ 2.1: Type Annotations (42/100) - REQUIRED (min: 60)

Score Gates Failing:
  â€¢ Overall Score: 68/100 (required: 75)
  â€¢ Tier 1 Average: 72/100 (required: 90)

Remediation:
  Run: agentready align . --attributes 1.1,2.1

This PR cannot be merged until policy requirements are met.
```

**Auto-Remediation (Optional)**
```bash
# Developer runs align to fix policy violations
$ agentready align . --policy-violations

Auto-detecting policy violations...
Found 2 attributes requiring fixes.

[Runs align on only failing required attributes]

âœ“ All policy requirements met
  Overall score: 78/100 (required: 75) âœ“
  Required attributes: 8/8 passing âœ“
```

**Scope for v3.0:**
- Policy configuration schema
- Hierarchical config (repo â†’ org â†’ global)
- Policy validation engine
- GitHub Action for CI/CD gates
- Policy violation reporting
- Exemption handling

**Deferred to v3.1+:**
- Policy dashboard (visual compliance tracking)
- Policy templates (starter policies for common scenarios)
- Time-based policy enforcement (grace periods)

---

## Alternative Feature Sets (If You Want Different Focus)

### Option B: User Value Over Enterprise

**Feature 1**: `agentready align` (same)
**Feature 2**: Continuous Alignment (GitHub Action that auto-fixes drift)
**Feature 3**: Org-Wide Dashboard (heatmap of scores across repos)

*Trade-off: Less validation rigor, more automation/visibility*

---

### Option C: AI-First Over Policy

**Feature 1**: `agentready align` (same)
**Feature 2**: Multi-Mode Judge LLM (same)
**Feature 3**: Predictive Fixes (suggest fixes before attributes fail)

*Trade-off: More ML innovation, less governance*

---

## Questions for You

### Q1: Core Feature Set

**Do you approve the proposed 3 features?**
- âœ… Feature 1: `agentready align` (automated alignment)
- âœ… Feature 2: Multi-Mode Judge LLM (validation)
- âœ… Feature 3: Policy Enforcement (governance)

**Or would you prefer a different combination?**
- Option B: Align + Continuous Alignment + Dashboard
- Option C: Align + Judge + Predictive Fixes
- Custom: Mix and match from options

---

### Q2: Feature Scope Adjustments

**For each approved feature, is the scope right?**

**Feature 1 (Align):**
- 14-16 fixable attributes OK? Or aim higher/lower?
- Interactive approval required? Or support --yes mode?
- PR creation only? Or also support direct commits?

**Feature 2 (Judge):**
- All 3 modes (validator/generator/ensemble) in v3.0? Or just validator?
- Anthropic + OpenAI sufficient? Or need local models too?
- Confidence threshold (0.85) reasonable?

**Feature 3 (Policy):**
- Blocking enforcement OK? Or warning-only to start?
- Org-level config sufficient? Or need user-level too?
- GitHub Action integration must-have? Or nice-to-have?

---

### Q3: Attribute Coverage Priority

**Which attributes are most important to fix in v3.0?**

Rank these by priority (1=highest):

**Tier 1 (Essential):**
- [ ] 1.1: CLAUDE.md Documentation
- [ ] 1.2: README Sections
- [ ] 1.3: .gitignore Patterns
- [ ] 1.4: Standard Directory Structure
- [ ] 1.5: Type Annotations

**Tier 2 (Critical):**
- [ ] 2.1: Test Coverage
- [ ] 2.2: Inline Documentation
- [ ] 2.3: Lock Files
- [ ] 2.4: Pre-commit Hooks
- [ ] 2.5: Conventional Commits

**Tier 3 (Important):**
- [ ] 3.1: Code Complexity
- [ ] 3.2: Linting Configuration
- [ ] 3.3: CI/CD Pipeline
- [ ] 3.4: Repomix Configuration

*We'll implement top 14-16 in v3.0, rest in v3.1+*

---

### Q4: Implementation Priorities

**For the 8-10 week timeline, what matters most?**

Rank these priorities (1=highest):
- [ ] Speed to first usable version (alpha quickly)
- [ ] Quality/testing (90% coverage from day 1)
- [ ] Documentation (comprehensive docs before launch)
- [ ] Feature completeness (all 3 features fully polished)
- [ ] User testing (extensive beta period)

---

### Q5: Success Criteria

**How do we know v3.0 is successful?**

Check all that apply:
- [ ] Fix success rate >80% (fixes work without manual editing)
- [ ] User adoption (X internal Red Hat teams using it)
- [ ] Score improvement (repos go from Silver â†’ Gold)
- [ ] Time savings (reduces manual alignment effort by X%)
- [ ] Policy compliance (X% of repos meet policy)
- [ ] User satisfaction (>4/5 rating from beta testers)

*What metrics matter to you?*

---

## Recommended Decisions (My Suggestions)

Based on your responses so far, I recommend:

1. **Core Features**: Approve proposed set (Align + Judge + Policy)
   - *Rationale: Balances innovation (AI), rigor (validation), governance (enterprise)*

2. **Feature Scopes**:
   - Align: 14 attributes (Tier 1 all + top 4 Tier 2)
   - Judge: All 3 modes (differentiation from competitors)
   - Policy: Blocking enforcement (you said "yes - this is important")

3. **Attribute Priority**:
   - Must-have: 1.1, 1.2, 1.3, 1.4, 1.5 (Tier 1 complete)
   - High priority: 2.1 (tests), 2.3 (lockfiles), 2.5 (commits)
   - Nice-to-have: 2.2, 2.4, 3.1, 3.2 (fill remaining budget)

4. **Implementation Priority**:
   - Speed to alpha (Week 2: working align + 5 fixers)
   - Quality second (Week 7: 90% coverage)
   - Feature completeness third (Week 8: all 3 features)
   - Docs fourth (Week 8: comprehensive guide)

5. **Success Criteria**:
   - Fix success rate >80%
   - 5+ Red Hat teams in beta
   - Repos improve by 1 tier (Bronze â†’ Silver, Silver â†’ Gold)

---

## Next Steps

**Please review and respond:**

1. **Approve/modify** the 3 core features
2. **Answer** the 5 questions above (or subset)
3. **Provide any additional constraints/priorities** I missed

Once you sign off, I'll:
1. Create detailed technical specification
2. Generate implementation task breakdown
3. Begin Phase 1 (Week 1) development

**Estimated time for your review**: 10-15 minutes
**Estimated time for spec generation after your sign-off**: 2-3 hours

---

## Appendix: What Gets Deferred to v3.1+

**Features NOT in v3.0:**
- Continuous alignment (scheduled auto-fixes)
- Org-wide dashboards (visualization)
- Predictive fixes (ML-based suggestions)
- Learning loop (fix improvement over time)
- Custom fixer plugins (user-defined fixers)
- IDE integration (LSP, VS Code extension)
- Real-time suggestions (as-you-type fixes)

**Attributes NOT fixable in v3.0:**
- ~10-12 remaining attributes (out of 25+ total)
- Complex refactoring (architectural changes)
- Domain-specific fixes (language-specific patterns)

**Rationale**: Focus delivers value faster than breadth
