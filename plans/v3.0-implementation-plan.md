# AgentReady v3.0 - Implementation Plan

**Date**: 2025-12-02
**Status**: APPROVED - Ready for implementation
**Timeline**: 8 weeks to stable v3.0.0
**Scope**: 3 core features, 10-12 fixable attributes

---

## Executive Summary

Based on your feature approval responses, v3.0 will deliver:

1. **`agentready align`** - Automated alignment with 10-12 fixable attributes
2. **Multi-Mode Judge LLM** - All 3 modes (validator/generator/ensemble), 3 providers (Anthropic/OpenAI/Local)
3. **Policy Enforcement** - Blocking enforcement with repo + org config levels

**Key Decisions:**
- Conservative attribute scope (10-12 vs 14-16): Quality over breadth
- High confidence threshold (0.90): Safety over speed
- All judge modes + local models: Full differentiation
- Speed prioritized: Alpha in Week 2, beta in Week 4
- Success metrics: User adoption, score improvement, policy compliance

---

## Approved Features & Scope

### Feature 1: `agentready align` - Automated Alignment ✅

**Target: 10-12 fixable attributes**

**Tier 1 (All 5 - Must Have):**
1. 1.1: CLAUDE.md Documentation (template)
2. 1.2: README Sections (template)
3. 1.3: .gitignore Patterns (template)
4. 1.4: Standard Directory Structure (template)
5. 1.5: Type Annotations (AI-powered)

**Top Tier 2 (5-7 attributes):**
1. 2.1: Test Coverage (AI-powered)
2. 2.2: Inline Documentation (AI-powered)
3. 2.3: Lock Files (template)
4. 2.4: Pre-commit Hooks (template)
5. 2.5: Conventional Commits (template)
6. (Stretch) 2.6: Error Handling (AI-powered)
7. (Stretch) 2.7: Logging (template)

**Implementation Split:**
- Template-based: 7 attributes (1.1, 1.2, 1.3, 1.4, 2.3, 2.4, 2.5)
- AI-powered: 3-5 attributes (1.5, 2.1, 2.2, +2.6, +2.7)
- **Target: 10 guaranteed, 12 if time permits**

**Workflow Modes:**
- ✅ Interactive approval (default): Approve/reject each attribute
- ✅ `--yes` mode: Auto-apply all fixes
- ✅ `--dry-run` mode: Preview without applying

**User Experience:**
```bash
# Interactive mode (default)
agentready align .

# Auto-apply mode
agentready align . --yes

# Preview mode
agentready align . --dry-run

# Specific attributes
agentready align . --attributes 1.1,1.2,2.3
```

---

### Feature 2: Multi-Mode Judge LLM Integration ✅

**All 3 Judge Modes:**
- ✅ **Validator**: Judge scores Claude's proposed fixes (primary mode)
- ✅ **Generator**: Use alternative LLM (GPT-4) instead of Claude
- ✅ **Ensemble**: Compare multiple LLMs, pick best fix

**All 3 Providers:**
- ✅ **Anthropic**: Claude Sonnet 4.5 (primary)
- ✅ **OpenAI**: GPT-4 (alternative)
- ✅ **Local**: Ollama, llama.cpp (offline support)

**Configuration:**
- Confidence threshold: **0.90** (conservative/safe)
- Configurable per-repo via `.agentready-config.yaml`
- CLI flags for mode selection

**User Experience:**
```bash
# Validator mode (default)
agentready align . --judge validator

# Generator mode (use GPT-4 instead of Claude)
agentready align . --judge generator --judge-model gpt-4

# Ensemble mode (compare both, pick best)
agentready align . --judge ensemble

# No judge (Claude only, faster)
agentready align . --no-judge

# Local model (offline)
agentready align . --judge validator --judge-provider local --judge-model llama3
```

**Configuration:**
```yaml
# .agentready-config.yaml
align:
  judge:
    enabled: true
    mode: validator              # validator|generator|ensemble
    provider: anthropic          # anthropic|openai|local
    confidence_threshold: 0.90   # Higher = safer

    # Ensemble mode settings
    ensemble:
      providers: [anthropic, openai]
      selection_strategy: highest_confidence
```

---

### Feature 3: Policy Enforcement ✅

**Enforcement Mode:**
- ✅ **Blocking**: Prevent merge on policy violations (enterprise-ready)

**Configuration Levels:**
- ✅ **Repository**: `.agentready-config.yaml` in repo root
- ✅ **Organization**: Org-wide policies (shared config)
- ❌ **Global/User**: Deferred to v3.1+ (simpler scope)

**Scope:**
- Policy configuration schema
- Hierarchical config (org overrides repo)
- GitHub Action integration (CI/CD gates)
- Policy violation reporting
- Exemption handling (repos, attributes)

**User Experience:**

**Define Policy (Org Admin):**
```yaml
# .agentready-config.yaml (org level)
policy:
  enabled: true
  enforcement_mode: blocking

  required_attributes:
    tier_1: all              # All Tier 1 required
    tier_2: ["2.1", "2.3"]   # Specific Tier 2

  score_gates:
    minimum_score: 75        # Gold certification

  exemptions:
    repos: ["legacy-app"]
    attributes: ["3.5"]
```

**Check Policy (Developer):**
```bash
# Check policy compliance
agentready align . --policy-check

# Auto-fix policy violations
agentready align . --policy-violations

# GitHub Action (automatic)
# Blocks PR merge if policy fails
```

---

## 8-Week Phased Implementation

### Phase 1: Core Align (Weeks 1-2) → v3.0.0-alpha1
**Priority: Speed to first usable version**

**Week 1: Foundation**
- BaseFixer architecture (pluggable, stateless)
- TemplateFixer implementation
- Git stash backup/rollback safety
- Interactive approval UX
- 2 template fixers (1.1 CLAUDE.md, 1.3 .gitignore)

**Week 2: Template Fixers**
- 5 more template fixers (1.2, 1.4, 2.3, 2.4, 2.5)
- CLI: `agentready align .`
- PR creation with GHA labels
- Workflow modes (--yes, --dry-run)
- Basic unit tests

**Deliverable**: Working align command, 7 template fixers, PR workflow

**Success Criteria**: Can run `agentready align .` and get CLAUDE.md + README fixes in a PR

---

### Phase 2: AI Integration (Weeks 3-4) → v3.0.0-beta1
**Priority: Quality/testing (90% coverage)**

**Week 3: AI Fixers + Judge (Anthropic)**
- AIFixer implementation (Claude API)
- Validator mode (judge scores fixes)
- 3 AI fixers (1.5, 2.1, 2.2)
- Confidence scoring (0.90 threshold)
- Unit tests for AI components

**Week 4: Multi-Provider Judge**
- OpenAI integration (GPT-4)
- Generator mode (GPT-4 as alternative)
- Ensemble mode (compare both)
- Judge configuration system
- 90% test coverage for fixer framework

**Deliverable**: 10 fixable attributes, 3 judge modes, 2 LLM providers

**Success Criteria**: AI fixes validated by judge, confidence scoring working

---

### Phase 3: Policy + Local Models (Weeks 5-6) → v3.0.0-rc1
**Priority: Feature completeness**

**Week 5: Policy Enforcement**
- Policy config schema
- Hierarchical config (repo → org)
- Policy validation engine
- GitHub Action for gates
- Violation reporting
- Ollama integration (basic)

**Week 6: Policy Polish + Integration**
- Blocking enforcement
- Exemption handling
- Policy CLI workflows
- End-to-end tests
- llama.cpp integration

**Deliverable**: Full policy enforcement, 3 LLM providers (Anthropic, OpenAI, Local)

**Success Criteria**: Org admins can define policies, PRs blocked on violations

---

### Phase 4: Quality & Launch (Weeks 7-8) → v3.0.0 stable
**Priority: Documentation**

**Week 7: Quality**
- 90% test coverage (all components)
- Performance (<30s for 1000 files)
- Error handling, edge cases
- Security review (API keys, input validation)
- Integration tests (full workflows)

**Week 8: Documentation & Launch**
- User guide (align, judge, policy)
- API reference (fixer development)
- CLI help text
- Migration guide (v2.x → v3.0)
- Release notes
- Internal beta (5+ Red Hat teams)

**Deliverable**: Production-ready v3.0.0

**Success Criteria**:
- 5+ teams using in production
- Repos improving by 1 tier (Bronze → Silver, Silver → Gold)
- 80%+ policy compliance

---

## Success Metrics (Your Approved Criteria)

**Primary Metrics:**
1. **User Adoption**: 5+ internal Red Hat teams using align in production
2. **Score Improvement**: Repos progress by 1 tier (Bronze → Silver → Gold)
3. **Policy Compliance**: 80%+ of repos meet defined policies

**How We'll Measure:**
- Track internal beta signups (Week 8)
- Before/after assessment scores (compare pre-align vs post-align)
- Policy check results from GitHub Actions

---

## Implementation Priorities (Your Ranking)

1. **Speed to first usable version** (alpha in Week 2)
2. **Quality/testing** (90% coverage by Week 7)
3. **Feature completeness** (all 3 features by Week 6)
4. **Documentation** (comprehensive by Week 8)
5. **User testing** (beta in Week 8)

**What this means:**
- Ship alpha fast (Week 2) even if incomplete
- Don't compromise on test coverage (90% gate)
- Deliver all 3 features before docs
- Extensive beta testing before v3.0.0 stable

---

## Technical Architecture Summary

### Core Classes

```python
# fixers/base.py
class BaseFixer(ABC):
    @property
    @abstractmethod
    def attribute_id(self) -> str:
        """Attribute this fixer addresses (e.g., '1.1')"""

    @abstractmethod
    async def can_fix(self, repository: Repository, finding: Finding) -> bool:
        """Can this fixer handle this finding?"""

    @abstractmethod
    async def generate_fix(self, repository: Repository, finding: Finding) -> FixProposal:
        """Generate fix proposal (stateless)"""

    async def validate_fix(self, repository: Repository, proposal: FixProposal) -> bool:
        """Validate proposed fix before applying"""

# fixers/template_fixer.py
class TemplateFixer(BaseFixer):
    """Template-based fixes (deterministic)"""
    template_path: Path

    async def generate_fix(self, repo, finding) -> FixProposal:
        # Render Jinja2 template with repo context
        content = self.render_template(repo)
        return FixProposal(
            attribute_id=self.attribute_id,
            files_modified=[target_file],
            diff=generate_diff(content),
            confidence=1.0  # Deterministic
        )

# fixers/ai_fixer.py
class AIFixer(BaseFixer):
    """LLM-powered fixes (non-deterministic)"""
    llm_client: LLMClient

    async def generate_fix(self, repo, finding) -> FixProposal:
        prompt = self._build_prompt(repo, finding)
        response = await self.llm_client.generate(prompt)
        return FixProposal(
            attribute_id=self.attribute_id,
            files_modified=response.files,
            diff=response.diff,
            confidence=response.confidence
        )

# services/judge_service.py
class JudgeService:
    def __init__(self, mode: JudgeMode, provider: str, threshold: float = 0.90):
        self.mode = mode
        self.provider = provider
        self.threshold = threshold

    async def judge(self, proposal: FixProposal) -> JudgeResult:
        if self.mode == JudgeMode.VALIDATOR:
            return await self._validate(proposal)
        elif self.mode == JudgeMode.GENERATOR:
            return await self._generate(proposal)
        elif self.mode == JudgeMode.ENSEMBLE:
            return await self._ensemble(proposal)
```

### Directory Structure

```
src/agentready/
├── cli/
│   ├── align.py              # agentready align command
│   └── policy.py             # agentready align --policy-check
├── services/
│   ├── align_service.py      # Orchestrates align workflow
│   ├── judge_service.py      # Multi-mode LLM judging
│   ├── policy_service.py     # Policy validation
│   └── llm_providers/
│       ├── anthropic.py      # Claude integration
│       ├── openai.py         # GPT-4 integration
│       └── local.py          # Ollama, llama.cpp
├── fixers/
│   ├── base.py              # BaseFixer ABC
│   ├── template_fixer.py    # Template-based
│   ├── ai_fixer.py          # AI-powered
│   ├── registry.py          # Fixer discovery
│   └── implementations/
│       ├── claude_md.py     # 1.1 fixer
│       ├── readme.py        # 1.2 fixer
│       └── ...
├── models/
│   ├── fix_proposal.py      # Fix proposal data
│   ├── judge_result.py      # Judge scoring
│   └── policy.py            # Policy config
└── templates/
    └── fixers/              # Jinja2 templates
```

---

## Configuration Schema

```yaml
# .agentready-config.yaml (v3.0)
version: "3.0.0"

# Align behavior
align:
  interactive: true          # Prompt per-attribute
  workflow: pr               # pr|local|commit

  judge:
    enabled: true
    mode: validator          # validator|generator|ensemble
    provider: anthropic      # anthropic|openai|local
    model: claude-sonnet-4.5 # or gpt-4, llama3
    confidence_threshold: 0.90

    ensemble:
      providers: [anthropic, openai]
      selection_strategy: highest_confidence

# Policy enforcement
policy:
  enabled: true
  enforcement_mode: blocking  # or warning

  required_attributes:
    tier_1: all
    tier_2: ["2.1", "2.3"]

  score_gates:
    minimum_score: 75
    tier_thresholds:
      tier_1: 90
      tier_2: 70

  exemptions:
    repos: ["legacy-*"]
    attributes: ["3.5"]
```

---

## Deferred to v3.1+

**Features NOT in v3.0:**
- Continuous alignment (scheduled auto-fixes)
- Org-wide dashboards (visualization)
- Predictive fixes (ML-based suggestions)
- Global/user-level config
- Custom fixer plugins
- IDE integration
- Real-time suggestions

**Attributes NOT fixable in v3.0:**
- 12-15 remaining attributes (out of 25+ total)
- Tier 3 & 4 (except top 2-4 from Tier 3)

---

## Next Steps

**Immediate (This Week):**
1. ✅ Feature set approved
2. ✅ Scope refined (10-12 attributes)
3. ✅ 8-week phased plan created
4. **Ready to begin Week 1 implementation**

**Week 1 Kickoff:**
- Set up fixer architecture
- Implement first 2 template fixers
- Basic interactive approval UX
- Git stash safety mechanism

**Questions Before Starting?**
- Any scope adjustments needed?
- Want detailed task breakdown for Week 1?
- Need architectural diagrams/specs?

---

**Status**: ✅ APPROVED - Ready for implementation
**Next Phase**: Week 1 kickoff (awaiting your go-ahead)
